{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存样本\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeData():#创造样本\n",
    "    for i in range(100):\n",
    "        x = np.random.uniform(-10., 10.)\n",
    "        eps = np.random.normal(0., 0.01)\n",
    "        y = 1.477 * x + 0.089 + eps\n",
    "        data.append([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(b, w, points): #计算误差\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)):\n",
    "        #print(\"i=\", i)\n",
    "        #print(\"point:\", points[i])\n",
    "        point = points[i]\n",
    "        x = point[0]#points[i, 0]\n",
    "        y = point[1]#points[i, 1]\n",
    "        totalError += (y - (w * x + b)) ** 2\n",
    "    \n",
    "    return totalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(b_current, w_current, points, lr):\n",
    "    # 计算误差函数在所有点上的导数，并更新 w,b\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    M = float(len(points)) # 总样本数\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 误差函数对 b 的导数：grad_b = 2(wx+b-y)，参考公式(2.3)\n",
    "        b_gradient += (2/M) * ((w_current * x + b_current) - y)\n",
    "        # 误差函数对 w 的导数：grad_w = 2(wx+b-y)*x，参考公式(2.2)\n",
    "        w_gradient += (2/M) * x * ((w_current * x + b_current) - y)\n",
    "    # 根据梯度下降算法更新 w',b',其中 lr 为学习率\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(points, starting_b, starting_w, lr, num_iterations):\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    # 根据梯度下降算法更新多次\n",
    "    for step in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        loss = mse(b, w, points)\n",
    "        if step % 50 == 0:\n",
    "            print(f'iteration:{step}, loss:{loss}, w:{w}, b:{b}')\n",
    "    return [b, w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    lr = 0.01 #学习率\n",
    "    initial_b = 0 # 初始化 b 为 0\n",
    "    initial_w = 0 # 初始化 w 为 0\n",
    "    num_iterations = 1000\n",
    "    # 训练优化 1000 次，返回最优 w*,b*和训练 Loss 的下降过程\n",
    "    [b, w] = gradient_descent(data, initial_b, initial_w, lr, num_iterations)\n",
    "    loss = mse(b, w, data)\n",
    "    print(f'Final loss:{loss}, w:{w}, b:{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, loss:910.0430288425885, w:0.9444175504986615, b:0.013475398778895023\n",
      "iteration:50, loss:0.07130502859534692, w:1.4773720906865404, b:0.06349980979886798\n",
      "iteration:100, loss:0.017697279159122718, w:1.477169648550405, b:0.07931127068366489\n",
      "iteration:150, loss:0.010513848723424396, w:1.4770955426021324, b:0.0850992124867404\n",
      "iteration:200, loss:0.009551270115533382, w:1.4770684153860587, b:0.08721794588904098\n",
      "iteration:250, loss:0.00942228472552171, w:1.4770584852000335, b:0.08799352922811997\n",
      "iteration:300, loss:0.009405000702481889, w:1.4770548501571221, b:0.08827743918828948\n",
      "iteration:350, loss:0.009402684645970228, w:1.4770535195136747, b:0.08838136724014678\n",
      "iteration:400, loss:0.009402374294742761, w:1.4770530324184663, b:0.08841941113250057\n",
      "iteration:450, loss:0.009402332707724727, w:1.4770528541124426, b:0.08843333747596184\n",
      "iteration:500, loss:0.009402327135070257, w:1.4770527888417573, b:0.0884384353518678\n",
      "iteration:550, loss:0.009402326388335496, w:1.4770527649487766, b:0.0884403014798163\n",
      "iteration:600, loss:0.009402326288273165, w:1.4770527562025146, b:0.08844098459442801\n",
      "iteration:650, loss:0.009402326274864752, w:1.4770527530008588, b:0.088441234655295\n",
      "iteration:700, loss:0.009402326273068147, w:1.477052751828861, b:0.0884413261925512\n",
      "iteration:750, loss:0.009402326272827494, w:1.4770527513998395, b:0.08844135970067005\n",
      "iteration:800, loss:0.009402326272795003, w:1.477052751242792, b:0.08844137196664881\n",
      "iteration:850, loss:0.009402326272790754, w:1.477052751185303, b:0.08844137645673172\n",
      "iteration:900, loss:0.009402326272790222, w:1.4770527511642588, b:0.08844137810037102\n",
      "iteration:950, loss:0.009402326272790125, w:1.4770527511565552, b:0.08844137870204144\n",
      "Final loss:0.009402326272790081, w:1.4770527511537683, b:0.08844137891970681\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
